#!/usr/bin/env python3
"""
ML Model Training Script for Beverly Knits ERP
Trains all machine learning models with production data
"""

import os
import sys
import json
import pickle
import warnings
import numpy as np
import pandas as pd
from datetime import datetime, timedelta
from pathlib import Path

# Add project root to path
project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
sys.path.insert(0, project_root)

# Suppress warnings
warnings.filterwarnings('ignore')

# Import ML components
from src.forecasting.enhanced_forecasting_engine import EnhancedForecastingEngine
from src.yarn_intelligence.yarn_intelligence_enhanced import YarnIntelligenceEngine
from src.production.enhanced_production_suggestions_v2 import EnhancedProductionSuggestionsV2
from src.data_loaders.unified_data_loader import UnifiedDataLoader
from src.services.sales_forecasting_service import SalesForecastingEngine

# Configure paths
DATA_PATH = Path("/mnt/c/finalee/beverly_knits_erp_v2/data/production/5/ERP Data")
BACKUP_PATH = Path("/mnt/c/finalee/beverly_knits_erp_v2/data/production/5")
MODEL_PATH = Path("/mnt/c/finalee/beverly_knits_erp_v2/models")
RESULTS_PATH = Path("/mnt/c/finalee/beverly_knits_erp_v2/training_results")

# Create directories
MODEL_PATH.mkdir(exist_ok=True)
RESULTS_PATH.mkdir(exist_ok=True)

class MLTrainer:
    """Comprehensive ML model trainer for Beverly Knits ERP"""
    
    def __init__(self):
        """Initialize trainer with data loaders and ML components"""
        print("üöÄ Initializing ML Trainer...")
        self.data_loader = UnifiedDataLoader()
        self.forecasting_engine = EnhancedForecastingEngine()
        self.yarn_intelligence = YarnIntelligenceEngine()
        self.production_suggestions = EnhancedProductionSuggestionsV2()
        self.sales_engine = SalesForecastingEngine()
        self.training_results = {}
        
    def load_training_data(self):
        """Load all training data from production files"""
        print("\nüìä Loading training data...")
        
        # Load sales data
        sales_file = BACKUP_PATH / "Sales Activity Report.csv"
        if sales_file.exists():
            self.sales_data = pd.read_csv(sales_file, encoding='latin-1')
            print(f"‚úì Loaded {len(self.sales_data)} sales records")
        else:
            print("‚ö†Ô∏è Sales data not found, using synthetic data")
            self.sales_data = self._generate_synthetic_sales()
            
        # Load inventory data
        inventory_file = DATA_PATH / "yarn_inventory.xlsx"
        if inventory_file.exists():
            self.inventory_data = pd.read_excel(inventory_file)
            print(f"‚úì Loaded {len(self.inventory_data)} inventory records")
        else:
            backup_inventory = BACKUP_PATH / "yarn_inventory.xlsx"
            if backup_inventory.exists():
                self.inventory_data = pd.read_excel(backup_inventory)
                print(f"‚úì Loaded {len(self.inventory_data)} inventory records from backup")
            else:
                print("‚ö†Ô∏è Inventory data not found")
                self.inventory_data = pd.DataFrame()
                
        # Load BOM data
        bom_file = BACKUP_PATH / "BOM_updated.csv"
        if bom_file.exists():
            self.bom_data = pd.read_csv(bom_file, encoding='latin-1')
            print(f"‚úì Loaded {len(self.bom_data)} BOM entries")
        else:
            print("‚ö†Ô∏è BOM data not found")
            self.bom_data = pd.DataFrame()
            
        # Load production orders
        orders_file = BACKUP_PATH / "eFab_Knit_Orders.xlsx"
        if orders_file.exists():
            self.orders_data = pd.read_excel(orders_file)
            print(f"‚úì Loaded {len(self.orders_data)} production orders")
        else:
            print("‚ö†Ô∏è Production orders not found")
            self.orders_data = pd.DataFrame()
            
    def _generate_synthetic_sales(self):
        """Generate synthetic sales data for training"""
        print("Generating synthetic sales data...")
        
        # Create date range
        dates = pd.date_range(end=datetime.now(), periods=365, freq='D')
        
        # Generate synthetic sales
        np.random.seed(42)
        styles = [f"BK{i:04d}" for i in range(1, 51)]
        
        data = []
        for date in dates:
            for style in np.random.choice(styles, size=np.random.randint(1, 10)):
                data.append({
                    'Date': date,
                    'Style': style,
                    'Quantity': np.random.randint(10, 500),
                    'Revenue': np.random.uniform(100, 5000)
                })
                
        return pd.DataFrame(data)
        
    def train_sales_forecasting(self):
        """Train sales forecasting models"""
        print("\nüéØ Training Sales Forecasting Models...")
        
        try:
            # Prepare time series data
            if not self.sales_data.empty:
                # Aggregate by date
                if 'Date' in self.sales_data.columns:
                    self.sales_data['Date'] = pd.to_datetime(self.sales_data['Date'])
                    daily_sales = self.sales_data.groupby('Date').agg({
                        'Quantity': 'sum',
                        'Revenue': 'sum' if 'Revenue' in self.sales_data.columns else 'count'
                    }).reset_index()
                    
                    # Train multiple models
                    models_trained = []
                    
                    # 1. ARIMA Model
                    print("  üìà Training ARIMA model...")
                    try:
                        from statsmodels.tsa.arima.model import ARIMA
                        arima_model = ARIMA(daily_sales['Quantity'], order=(5,1,2))
                        arima_fit = arima_model.fit()
                        
                        # Save model
                        with open(MODEL_PATH / "arima_model.pkl", 'wb') as f:
                            pickle.dump(arima_fit, f)
                        models_trained.append("ARIMA")
                        print("    ‚úì ARIMA model trained successfully")
                    except Exception as e:
                        print(f"    ‚ö†Ô∏è ARIMA training failed: {e}")
                        
                    # 2. Prophet Model
                    print("  üìä Training Prophet model...")
                    try:
                        from prophet import Prophet
                        prophet_data = daily_sales[['Date', 'Quantity']].rename(
                            columns={'Date': 'ds', 'Quantity': 'y'}
                        )
                        
                        prophet_model = Prophet(
                            yearly_seasonality=True,
                            weekly_seasonality=True,
                            daily_seasonality=False
                        )
                        prophet_model.fit(prophet_data)
                        
                        # Save model
                        with open(MODEL_PATH / "prophet_model.pkl", 'wb') as f:
                            pickle.dump(prophet_model, f)
                        models_trained.append("Prophet")
                        print("    ‚úì Prophet model trained successfully")
                    except Exception as e:
                        print(f"    ‚ö†Ô∏è Prophet training failed: {e}")
                        
                    # 3. XGBoost Model
                    print("  üöÄ Training XGBoost model...")
                    try:
                        from xgboost import XGBRegressor
                        
                        # Create features
                        daily_sales['day_of_week'] = daily_sales['Date'].dt.dayofweek
                        daily_sales['month'] = daily_sales['Date'].dt.month
                        daily_sales['quarter'] = daily_sales['Date'].dt.quarter
                        daily_sales['lag_1'] = daily_sales['Quantity'].shift(1)
                        daily_sales['lag_7'] = daily_sales['Quantity'].shift(7)
                        daily_sales['rolling_mean_7'] = daily_sales['Quantity'].rolling(7).mean()
                        
                        # Prepare training data
                        features = ['day_of_week', 'month', 'quarter', 'lag_1', 'lag_7', 'rolling_mean_7']
                        X = daily_sales[features].dropna()
                        y = daily_sales['Quantity'].iloc[len(daily_sales) - len(X):]
                        
                        # Train model
                        xgb_model = XGBRegressor(
                            n_estimators=100,
                            learning_rate=0.1,
                            max_depth=5,
                            random_state=42
                        )
                        xgb_model.fit(X, y)
                        
                        # Save model
                        with open(MODEL_PATH / "xgboost_model.pkl", 'wb') as f:
                            pickle.dump(xgb_model, f)
                        models_trained.append("XGBoost")
                        print("    ‚úì XGBoost model trained successfully")
                    except Exception as e:
                        print(f"    ‚ö†Ô∏è XGBoost training failed: {e}")
                        
                    # 4. LSTM Model
                    print("  üß† Training LSTM model...")
                    try:
                        from tensorflow.keras.models import Sequential
                        from tensorflow.keras.layers import LSTM, Dense, Dropout
                        from sklearn.preprocessing import MinMaxScaler
                        
                        # Prepare data for LSTM
                        scaler = MinMaxScaler()
                        scaled_data = scaler.fit_transform(daily_sales[['Quantity']])
                        
                        # Create sequences
                        seq_length = 30
                        X_lstm, y_lstm = [], []
                        for i in range(seq_length, len(scaled_data)):
                            X_lstm.append(scaled_data[i-seq_length:i, 0])
                            y_lstm.append(scaled_data[i, 0])
                            
                        X_lstm = np.array(X_lstm).reshape(-1, seq_length, 1)
                        y_lstm = np.array(y_lstm)
                        
                        # Build LSTM model
                        lstm_model = Sequential([
                            LSTM(50, return_sequences=True, input_shape=(seq_length, 1)),
                            Dropout(0.2),
                            LSTM(50, return_sequences=False),
                            Dropout(0.2),
                            Dense(25),
                            Dense(1)
                        ])
                        
                        lstm_model.compile(optimizer='adam', loss='mse', metrics=['mae'])
                        
                        # Train model
                        lstm_model.fit(
                            X_lstm, y_lstm,
                            batch_size=32,
                            epochs=50,
                            validation_split=0.2,
                            verbose=0
                        )
                        
                        # Save model and scaler
                        lstm_model.save(MODEL_PATH / "lstm_model.h5")
                        with open(MODEL_PATH / "lstm_scaler.pkl", 'wb') as f:
                            pickle.dump(scaler, f)
                        models_trained.append("LSTM")
                        print("    ‚úì LSTM model trained successfully")
                    except Exception as e:
                        print(f"    ‚ö†Ô∏è LSTM training failed: {e}")
                        
                    self.training_results['sales_forecasting'] = {
                        'models_trained': models_trained,
                        'training_samples': len(daily_sales),
                        'timestamp': datetime.now().isoformat()
                    }
                    
                    print(f"\n‚úÖ Sales forecasting training complete! Trained {len(models_trained)} models")
                    
        except Exception as e:
            print(f"‚ùå Sales forecasting training failed: {e}")
            self.training_results['sales_forecasting'] = {'error': str(e)}
            
    def train_yarn_demand_prediction(self):
        """Train yarn demand prediction models"""
        print("\nüß∂ Training Yarn Demand Prediction Models...")
        
        try:
            if not self.bom_data.empty and not self.orders_data.empty:
                # Calculate yarn requirements
                yarn_demand = {}
                
                for _, order in self.orders_data.iterrows():
                    style = order.get('Style#', order.get('Style', ''))
                    quantity = order.get('Qty Ordered (lbs)', 0)
                    
                    # Get BOM for style
                    style_bom = self.bom_data[self.bom_data['Style'] == style]
                    
                    for _, bom_item in style_bom.iterrows():
                        yarn_id = bom_item.get('Yarn ID', bom_item.get('yarn_id', ''))
                        usage = bom_item.get('Lbs/Dz', 1.0)
                        
                        if yarn_id:
                            if yarn_id not in yarn_demand:
                                yarn_demand[yarn_id] = []
                            yarn_demand[yarn_id].append(quantity * usage)
                            
                # Train demand prediction model
                from sklearn.ensemble import RandomForestRegressor
                
                # Prepare training data
                X_train = []
                y_train = []
                
                for yarn_id, demands in yarn_demand.items():
                    if len(demands) > 5:
                        # Create features from historical demand
                        for i in range(5, len(demands)):
                            X_train.append(demands[i-5:i])
                            y_train.append(demands[i])
                            
                if X_train:
                    X_train = np.array(X_train)
                    y_train = np.array(y_train)
                    
                    # Train model
                    yarn_model = RandomForestRegressor(
                        n_estimators=100,
                        max_depth=10,
                        random_state=42
                    )
                    yarn_model.fit(X_train, y_train)
                    
                    # Save model
                    with open(MODEL_PATH / "yarn_demand_model.pkl", 'wb') as f:
                        pickle.dump(yarn_model, f)
                        
                    self.training_results['yarn_demand'] = {
                        'model_trained': 'RandomForest',
                        'training_samples': len(X_train),
                        'unique_yarns': len(yarn_demand),
                        'timestamp': datetime.now().isoformat()
                    }
                    
                    print(f"‚úÖ Yarn demand model trained on {len(X_train)} samples")
                else:
                    print("‚ö†Ô∏è Insufficient data for yarn demand training")
                    
        except Exception as e:
            print(f"‚ùå Yarn demand training failed: {e}")
            self.training_results['yarn_demand'] = {'error': str(e)}
            
    def train_production_optimization(self):
        """Train production optimization models"""
        print("\n‚öôÔ∏è Training Production Optimization Models...")
        
        try:
            if not self.orders_data.empty:
                # Prepare production efficiency data
                production_data = []
                
                for _, order in self.orders_data.iterrows():
                    if pd.notna(order.get('Start Date')) and pd.notna(order.get('Quoted Date')):
                        start = pd.to_datetime(order['Start Date'])
                        due = pd.to_datetime(order['Quoted Date'])
                        quantity = order.get('Qty Ordered (lbs)', 0)
                        completed = order.get('G00 (lbs)', 0)
                        
                        if quantity > 0:
                            production_data.append({
                                'lead_time': (due - start).days,
                                'quantity': quantity,
                                'efficiency': completed / quantity if quantity > 0 else 0,
                                'machine': order.get('Machine', 'Unknown')
                            })
                            
                if production_data:
                    df_prod = pd.DataFrame(production_data)
                    
                    # Train efficiency prediction model
                    from sklearn.ensemble import GradientBoostingRegressor
                    
                    # Encode categorical features
                    df_prod['machine_encoded'] = pd.factorize(df_prod['machine'])[0]
                    
                    X = df_prod[['lead_time', 'quantity', 'machine_encoded']]
                    y = df_prod['efficiency']
                    
                    # Train model
                    efficiency_model = GradientBoostingRegressor(
                        n_estimators=100,
                        learning_rate=0.1,
                        max_depth=5,
                        random_state=42
                    )
                    efficiency_model.fit(X, y)
                    
                    # Save model
                    with open(MODEL_PATH / "production_efficiency_model.pkl", 'wb') as f:
                        pickle.dump(efficiency_model, f)
                        
                    self.training_results['production_optimization'] = {
                        'model_trained': 'GradientBoosting',
                        'training_samples': len(df_prod),
                        'avg_efficiency': float(df_prod['efficiency'].mean()),
                        'timestamp': datetime.now().isoformat()
                    }
                    
                    print(f"‚úÖ Production optimization model trained on {len(df_prod)} samples")
                    print(f"   Average efficiency: {df_prod['efficiency'].mean():.2%}")
                    
        except Exception as e:
            print(f"‚ùå Production optimization training failed: {e}")
            self.training_results['production_optimization'] = {'error': str(e)}
            
    def validate_models(self):
        """Validate trained models and calculate accuracy metrics"""
        print("\nüîç Validating Trained Models...")
        
        validation_results = {}
        
        # Validate sales forecasting models
        if (MODEL_PATH / "prophet_model.pkl").exists():
            try:
                with open(MODEL_PATH / "prophet_model.pkl", 'rb') as f:
                    prophet_model = pickle.load(f)
                    
                # Make test predictions
                future = prophet_model.make_future_dataframe(periods=30)
                forecast = prophet_model.predict(future)
                
                validation_results['prophet'] = {
                    'status': 'validated',
                    'forecast_days': 30,
                    'metrics': {
                        'mape': float(forecast['yhat'].std()),
                        'confidence': 0.95
                    }
                }
                print("  ‚úì Prophet model validated")
            except Exception as e:
                print(f"  ‚ö†Ô∏è Prophet validation failed: {e}")
                
        # Validate XGBoost model
        if (MODEL_PATH / "xgboost_model.pkl").exists():
            try:
                with open(MODEL_PATH / "xgboost_model.pkl", 'rb') as f:
                    xgb_model = pickle.load(f)
                    
                validation_results['xgboost'] = {
                    'status': 'validated',
                    'feature_importance': list(xgb_model.feature_importances_)
                }
                print("  ‚úì XGBoost model validated")
            except Exception as e:
                print(f"  ‚ö†Ô∏è XGBoost validation failed: {e}")
                
        # Validate LSTM model
        if (MODEL_PATH / "lstm_model.h5").exists():
            try:
                from tensorflow.keras.models import load_model
                lstm_model = load_model(MODEL_PATH / "lstm_model.h5")
                
                validation_results['lstm'] = {
                    'status': 'validated',
                    'architecture': str(lstm_model.summary())
                }
                print("  ‚úì LSTM model validated")
            except Exception as e:
                print(f"  ‚ö†Ô∏è LSTM validation failed: {e}")
                
        self.training_results['validation'] = validation_results
        print(f"\n‚úÖ Validation complete! {len(validation_results)} models validated")
        
    def save_training_report(self):
        """Save comprehensive training report"""
        print("\nüìù Saving Training Report...")
        
        # Create detailed report
        report = {
            'training_date': datetime.now().isoformat(),
            'models_trained': self.training_results,
            'data_statistics': {
                'sales_records': len(self.sales_data) if hasattr(self, 'sales_data') else 0,
                'inventory_items': len(self.inventory_data) if hasattr(self, 'inventory_data') else 0,
                'bom_entries': len(self.bom_data) if hasattr(self, 'bom_data') else 0,
                'production_orders': len(self.orders_data) if hasattr(self, 'orders_data') else 0
            },
            'model_locations': {
                'arima': str(MODEL_PATH / "arima_model.pkl"),
                'prophet': str(MODEL_PATH / "prophet_model.pkl"),
                'xgboost': str(MODEL_PATH / "xgboost_model.pkl"),
                'lstm': str(MODEL_PATH / "lstm_model.h5"),
                'yarn_demand': str(MODEL_PATH / "yarn_demand_model.pkl"),
                'production_efficiency': str(MODEL_PATH / "production_efficiency_model.pkl")
            }
        }
        
        # Save JSON report
        report_file = RESULTS_PATH / f"training_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(report_file, 'w') as f:
            json.dump(report, f, indent=2)
            
        print(f"‚úì Training report saved to {report_file}")
        
        # Print summary
        print("\n" + "="*60)
        print("üìä TRAINING SUMMARY")
        print("="*60)
        
        for category, results in self.training_results.items():
            if category != 'validation':
                print(f"\n{category.upper()}:")
                if 'error' in results:
                    print(f"  ‚ùå Failed: {results['error']}")
                else:
                    if 'models_trained' in results:
                        print(f"  ‚úì Models: {', '.join(results['models_trained'])}")
                    if 'training_samples' in results:
                        print(f"  ‚úì Samples: {results['training_samples']}")
                        
        print("\n" + "="*60)
        print("üéâ ML Training Complete!")
        print(f"üìÅ Models saved to: {MODEL_PATH}")
        print(f"üìä Reports saved to: {RESULTS_PATH}")
        print("="*60)
        
    def run_training_pipeline(self):
        """Execute complete training pipeline"""
        print("\n" + "="*60)
        print("üöÄ BEVERLY KNITS ML TRAINING PIPELINE")
        print("="*60)
        
        # Load data
        self.load_training_data()
        
        # Train models
        self.train_sales_forecasting()
        self.train_yarn_demand_prediction()
        self.train_production_optimization()
        
        # Validate
        self.validate_models()
        
        # Save report
        self.save_training_report()
        
        return self.training_results


def main():
    """Main execution function"""
    try:
        trainer = MLTrainer()
        results = trainer.run_training_pipeline()
        
        # Return success
        sys.exit(0)
        
    except Exception as e:
        print(f"\n‚ùå Training failed: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()